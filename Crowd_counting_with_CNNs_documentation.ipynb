{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crowd Counting using Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The need for an accurate crowd counting is as old as the mankind itself. Being it for the use of counting the sizes of animal herds, enemy armies or assessing the audience size for safety reasons, people could have always taken a significant advantage of knowing the precise crowd counts. With the introduction of computer vision and crowd counting algorithms using convolutional neural networks these counting predictions became more accurate than ever before. These aspects became one of the major inspirations for our team to take on this topic and deep dive into the crowd counting state-of-the-art techniques for our Integrify graduation project.\n",
    "\n",
    "Our team consists of [Nhu Nguyen](https://github.com/joycenhunguyen), [Thuong Nguyen](https://github.com/Thuong89) and [Radim Musalek](https://github.com/RadimMusalek)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project is devided into the following parts:\n",
    "1. Theoretical introduction of two state-of-the-art models:\n",
    "    - multi-column convolutional neural network model (MCNN)\n",
    "    - dilated convolutional neural networks model (dilated CNNs)\n",
    "2. ShanghaiTech datasets introduction (the datasets used for the models training)\n",
    "3. Model introduction\n",
    "4. Implementation and deployment\n",
    "5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crowd counting - purpose and use\n",
    "\n",
    "As mentioned in the project's introduction the crowd counting techniques has been around for the bigger part of mankind's history. However, in the modern world the crowd counting algorithms' use can be extended from the purposes named above beyond its human-centered application into other areas where crowds are formed such as animal herds, on-land and on-sea traffic, concentrations of cancer cells, bacteria and other microbiology, medical, etc. applications.\n",
    "\n",
    "Although in our work we apply the model to a static single-image crowd counting problem it can be used also for crowd counting from videos. Therefore, bringing an important feature for real-time evaluation problems where the size of a crowd needs to be assessed continuously. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original paper introducing the ShanghaiTech datasets and using MCNN model\n",
    "\n",
    "Our project is based on the [paper published by Yingying Zhang, Desen Zhou, Siqin Chen, Shenghua Gao and Yi Ma of the Shanghaitech University](https://github.com/joycenhunguyen/Crowd-counting/blob/main/linked_docs/Zhang_Single-Image_Crowd_Counting_CVPR_2016_paper.pdf) in 2016 which introduced the ShanghaiTech datasets A and B, and the state-of-the-art crowd counting model using the MCNN.\n",
    "\n",
    "The proposed MCNN model contains three columns of CNNs whose filters have different sizes. Input of the MCNN is the image, and its output is a crowd density map whose integral gives the overall crowd count. For each column filters of different sizes are used to model the density maps corresponding to heads of different scales. For instance, filters with larger receptive fields are more useful for modeling the density maps corresponding to larger heads. The same network structures are used for all columns with the exception of the sizes and numbers of filters. Max pooling is applied for each 2×2 region and Rectified linear unit (ReLU) is adopted as the activation function.\n",
    "\n",
    "To reduce the computational complexity, the authors used fewer filters for CNNs with larger filters. They stacked the output feature maps of all CNNs and mapped them to a density map. To map the features maps to the density map, they adopted filters whose sizes are 1×1. Then Euclidean distance is used to measure the difference between the estimated density map and ground truth.\n",
    "\n",
    "For better understanding the visualisation of the model's architecture is below:\n",
    "\n",
    "<img src=\"linked_docs/MCNN_model.png\" align=\"center\" width=\"724\" height=\"393\">\n",
    "\n",
    "To evaluate the model's performance on this (and other) dataset in their paper the authors chose the Mean Absolute Error (MAE) and Mean Squared Error (MSE). Their results of both the Part A and Part B of the Shanghaitech dataset can be found in the below table. We selected these performance evaluators also for the other models to be able to compare their performances.\n",
    "\n",
    "| Dataset |  MAE  |  MSE  |\n",
    "| :-----: | :---: | :---: |\n",
    "|   SHA   | 110.2 | 173.2 |\n",
    "|   SHB   |  26.4 |  41.3 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved crowd counting model using dilated CNNs\n",
    "\n",
    "The paper [CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes by Yuhong Li, Xiaofan Zhang, and Deming Chen of the Beijing University of Posts and Telecommunications and University of Illinois at Urbana-Champaign](https://github.com/joycenhunguyen/Crowd-counting/blob/main/linked_docs/CSRNet_Dilated_Convolutional_Neural_Networks_for_U.pdf) was published in March 2018 and introduced the dilated CNNs model for solving crowd counting tasks.\n",
    "\n",
    "The CSRNet model is trying to fix some of the disadvantages of the earlier models such as the large training time and less effective branch structures, e.g. such as in the above explained original model using MCNN.\n",
    "\n",
    "The first 10 convolutional layers of the model are fine-tuned from a well-trained VGG-16. For the following 6 layers at the back-end of the model, the initial values come from a Gaussian initialization with 0.01 standard deviation. Stochastic gradient descent (SGD) is applied with fixed learning rate at 1e-6 during training. Also, the authors chose the Euclidean distance to measure the difference between the ground truth and the estimated density map we generated which is similar to other works, e.g. the original Shaghaitech paper introduced earlier.\n",
    "\n",
    "The following data augmentation process was used for the model training purposes - the authors cropped 9 patches from each image at different locations with 1/4 size of the original image. The first four patches contain four quarters of the image without overlapping while the other five patches are randomly cropped from the input image. After that, they mirrored the patches so that they doubled the training set.\n",
    "\n",
    "The authors achived the best results with the version B of their model architeture, i.e. one using the dilation rate = 2 for all the convolution layers in the back-end part, which was used also for their model's performance evalution on all datasets cover in their paper.\n",
    "\n",
    "For better understanding and comparison to the MCNN model, the visualisation of the model's architecture is below:\n",
    "\n",
    "<img src=\"linked_docs/Dilated_CNNs_model.png\" align=\"center\" width=\"357\" height=\"452\">\n",
    "\n",
    "It delivered a significant improvement in both the MAE and MSE results compare to the previously seen numbers that used the MCNN model.\n",
    "\n",
    "| Dataset |  MAE  |  MSE  |\n",
    "| :-----: | :---: | :---: |\n",
    "|   SHA   |  68.2 | 115.0 |\n",
    "|   SHB   |  10.6 |  16.0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training dataset - Shanghaitech\n",
    "\n",
    "The dataset called Shanghaitech was introduced in the MCNN paper described earlier. It includes nearly 1,200 large-scale crowd images with around 330,000 labeled heads. The dataset consists of two parts: Part A and Part B. Images in Part A are randomly crawled from the Internet, most of them have a large number of people. Part B images are taken from busy streets of metropolitan areas in Shanghai by the authors who also manually annotated images in both parts. No two images in this dataset are taken from the same viewpoint.\n",
    "\n",
    "The crowd density varies significantly between the two subsets, making accurate estimation of the crowd more challenging than most existing datasets. Both Part A and Part B are divided into training and testing: 300 images of Part A are used for training and the remaining 182 images for testing;, and 400 images of Part B are for training and 316 for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The model which we use in our deployment is the [Zheng Peng's Keras implemention of the dilated CNNs methodology](https://github.com/ZhengPeng7/CSRNet-Keras) proposed by the CSRNet model paper described earlier in our work, its version B to be more specific. Zheng Peng was able to further improve the dilated CNN model's performance on both datasets as can be seen from the MAE/MSE overview below. This is the best performing model on the ShanghaiTech datasets we were able to find during our research for this project, however, since it had been created in July 2019 (i.e. relatively \"old\" considering the rapid progress in the world of machine learning), we acknowledge it is likely that there might be even more accurate and/or faster learning model which we just didn't come across.\n",
    "\n",
    "Zheng Peng's CSRNet model uses the same architecture as the original CSRNet model, however, the SGD's learning rate applied during the training is 1e-5 compare to the original's 1e-6 and the loss function was set to MSE instead of Euclidean distance.\n",
    "\n",
    "Again the MAE and MSE results indicating the model's performance improvement are displayed below:\n",
    "\n",
    "| Dataset |  MAE  |  MSE   |\n",
    "| :-----: | :---: | :---:  |\n",
    "|   SHA   | 67.98 | 103.24 |\n",
    "|   SHB   |  8.31 |  14.36 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation and deployment\n",
    "\n",
    "The deployment is made with Streamlit and Docker to deploy model on the web representation. The product called “Crowd-counting App” allows to take images as input and result outputs as heatmap and number of people in the images.\n",
    "\n",
    "<img src=\"linked_docs/APP_deployment.jpg\" align=\"center\" width=\"1024\" height=\"576\">\n",
    "\n",
    "As we can see from the **APP FOLDER** section in the above image, our app folder contains 9 files and 2 folders:\n",
    "- The main file of the app is “first_app.py” where our team conducted product deployment with Streamlit, Python packages (PIL, os, Numpy, Matplotlib), HTML, and CSS.\n",
    "- The second main file is “engine.py” to feed the “first_app.py” with its result. The “engine.py” takes other files “.py”, best weights, and best model during its execution. \n",
    "- Folder “models” stores model architecture.\n",
    "- Folder “part” to store user’s input images.\n",
    "\n",
    "It is important to notice that our app contains two models, A for Dense and B for Non-dense image respectively, which correspond to the Shanghaitech dataset part A and B introduced above. Model A and Model B are built on the same deep learning model architecture (CSRNet), but they receive different weights. The condition is set on “first_app.py” to select which best weight (A or B) should be plugged into the deep learning model execution “engine.py”.  The workflow of model A vs B can be illustrated in the **APP WORKFLOW** in the above image.\n",
    "\n",
    "Finally, the output of the whole model has its web representation in which the layout is divided into two panels. The left panel receives the user's input, whereas the right panel shows the input instructions and the result of the app, i.e. the heatmap and the count of the persons in the crowd predicted by the CSRNet model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-27T10:24:54.363162Z",
     "start_time": "2021-03-27T10:24:54.261386Z"
    }
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "The goal of this project was applying a CNN model on a crowd counting problem and deploying it on the web to showcase our ability to utilise a state-of-the-art solution with real-life implications.\n",
    "\n",
    "We got familiar with couple of scientific papers proposing various solutions to the crowd counting problem utilising CNN architectures and used MAE and MSE to compare the performance of these models on the Shanghaitech dataset. The performance overview of those and also other known models is presented below.\n",
    "\n",
    "| Method |  MAE - A | MSE - A | MAE - B | MSE - B |\n",
    "| :-----: | :---: | :---: | :---: | :---: |\n",
    "| Zhang et al. | 181.8 | 277.7 | 32.0 | 49.8 |\n",
    "| Marsden et al. | 126.5 | 173.5 | 23.8 | 33.1 |\n",
    "| MCNN | 110.2 | 173.2 | 26.4 | 41.3 |\n",
    "| Cascaded-MTL | 101.3 | 152.4 | 20.0 | 31.1 |\n",
    "| Switching-CNN | 90.4 | 135.0 | 21.6 | 33.4 |\n",
    "| CP-CNN | 73.6 | 106.4 | 20.1 | 30.1 |\n",
    "| CSRNet (paper) | 68.2 | 115.0 | 10.6 | 16.0 |\n",
    "| CSRNet (by Zheng Peng) | 68.0 | 103.2 | 8.3 | 14.4 |\n",
    "\n",
    "From the proposed solutions we implemented and deployed the best performing model called CSRNet which had been proposed in the paper by Yuhong Li, Xiaofan Zhang, and Deming Chen of the Beijing University of Posts and Telecommunications and University of Illinois at Urbana-Champaign and further improved by Zheng Peng whose trained model and weights we also applied.\n",
    "\n",
    "In our project we used a single-image implementation of the CSRNet model but other applications could be evalutated in future projects too. It would be interesting to see how the model would perform in applications such as solutions using a video as an input or even implementing the model with a real-time video input. It is possible, however, that this model would perform poorly in such implementations since the paper states its application to datasets with single images only."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
